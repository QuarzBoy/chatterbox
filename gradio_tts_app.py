import torch
import torchaudio as ta
import re
from chatterbox.mtl_tts import ChatterboxMultilingualTTS

def sentence_split(text):
    # –†–∞–∑–±–∏–≤–∞–µ–º –ø–æ .!? –∏ —É–±–∏—Ä–∞–µ–º –ø—É—Å—Ç—ã–µ —Å—Ç—Ä–æ–∫–∏
    return [s.strip() for s in re.split(r'(?<=[.!?])\s+', text) if s.strip()]

def tts_no_cfg(text, ref_audio, output_path, pause_sec=0.5):
    model = ChatterboxMultilingualTTS.from_pretrained(device="cuda")
    sr = model.sr

    sentences = sentence_split(text)
    print(f"üîé –†–∞–∑–±–∏–ª–∏ —Ç–µ–∫—Å—Ç –Ω–∞ {len(sentences)} –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π")

    results = []
    pause = torch.zeros((1, int(sr * pause_sec)))

    for idx, sentence in enumerate(sentences, 1):
        print(f"‚ñ∂Ô∏è –ì–µ–Ω–µ—Ä–∞—Ü–∏—è {idx}/{len(sentences)}: {sentence}")
        wav = model.generate(
            sentence,
            language_id="ru",
            audio_prompt_path=ref_audio,
            exaggeration=0.6,
            temperature=0.6,
            cfg_weight=0.0,   # ‚ö° –æ—Ç–∫–ª—é—á–∞–µ–º CFG
            min_p=0.0,
            top_p=0.9,
            repetition_penalty=1.0
        )

        if wav.dim() == 1:
            wav = wav.unsqueeze(0)
        elif wav.shape[0] > wav.shape[1]:
            wav = wav.T

        results.append(wav.cpu())
        results.append(pause)

    final_wav = torch.cat(results, dim=1)
    ta.save(output_path, final_wav, sr)
    print(f"‚úÖ –§–∞–π–ª —Å–æ—Ö—Ä–∞–Ω—ë–Ω: {output_path}")

if __name__ == "__main__":
    TEXT = ("–ù–∏ –∑–ª–∞, –Ω–∏ –¥–æ–±—Ä–∞ –Ω–µ—Ç. –°–º—ã—Å–ª–∞ –Ω–µ—Ç. "
            "–°–º—ã—Å–ª –∑–∞–¥–∞—ë—Ç —Å–µ–±–µ –∫–∞–∂–¥—ã–π —Å–∞–º. "
            "–°–≤–æ–±–æ–¥—ã –≤–æ–ª–∏ –Ω–µ—Ç. "
            "–û—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç–∏ –Ω–∏–∫—Ç–æ –Ω–µ –ø—Ä–∏–Ω–∏–º–∞–µ—Ç.")
    REF_AUDIO = r"D:\Proect\Chattrebox\test1\chatterbox\yuuechka_anime_web_girl.wav"
    OUTPUT = r"D:\Proect\Chattrebox\test1\chatterbox\output_no_cfg.wav"

    tts_no_cfg(TEXT, REF_AUDIO, OUTPUT, pause_sec=0.4)
